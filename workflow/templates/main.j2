# Summary

This directory contains stratifications for the reference {refname}.

{% if haplotypes|length == 1 -%}
This reference is diploid. The files here contain regions for the 
{{ haplotypes[0] }} haplotype.

{% elif haplotypes|length == 2 -%}
This reference is diploid. The files here contain regions for both 
{{ haplotypes[0] }} and {{ haplotypes[1] }} haplotypes.

{% endif -%}
Each subdirectory contains different stratifications grouped by type. These are
summarized below.

{% if have_low_complexity -%}
## Low Complexity

Regions with different types and sizes of low complexity sequence, e.g.,
homopolymers, STRs, VNTRs and other locally repetitive sequences.

{% endif -%}
{% if have_segdups -%}
## Segmental Duplications

Regions with segmental duplications (generally defined as repeated regions >1kb
with >90% similarity).

{% endif -%}
{% if have_sex -%}
## XY

Chomosome XY specific regions such as pseudoautosomal regions (PAR), XTR or
ampliconic.

{% endif -%}
{% if have_functional -%}
## Functional

Regions to stratify variants inside and outside coding regions.

{% endif -%}
{% if have_gc -%}
## GCcontent

Regions with different ranges (%) of GC content.

{% endif -%}
{% if have_mappability -%}
## Mappability

Regions where short read mapping can be challenging.

{% endif -%}
{% if otherdiff is not none -%}
## Other Difficult

{% if otherdiff[0]|length > 0 -%}
This category contains stratifications for miscellaneously difficult regions of
the genome, including:
{% for desc in otherdiff[0] -%}
- {{ desc }}
{% endfor -%}
{% if otherdiff[1] -%}
- and more, which are described in the accompanying README
{% endif -%}
{% else -%}
This category contains stratifications for miscellaneously difficult regions of
the genome, which are described in the accompanying README.
{%- endif %}
{%- endif %}
{% if have_telomeres -%}
## Telomeres

Telomeric regions.

{% endif -%}
{% if have_union -%}
## Union

Regions with different general types of difficult regions or any type of
difficult region or complex variant. For example, performance can be measured in
just "easy" or "all difficult" regions of the genome.

{% endif -%}
{% for other in other_levels -%}
## {{ other.key }}

{{ other.desc }}

These are described in futher detail in the accompanying README.

{% endfor -%}
# Reference Source

{{ ref_src }}

# Workflow overview

The following is very general. For more specifics on each stratification
category outlined above, consult the README under the appropriate directory.

1. Download reference FASTA and filter out all but chromosomes 1-22/X/Y. Any
   provided FASTA that is not in bgzip format will be forced to bgzip. In the
   case of diploid references, one or two FASTAs may be downloaded depending on
   if the haplotypes are combined into one file or not.

2. Download and standardize all necessary source files (bed, GFF, etc):

   1. Many of these are not true "bed files" but are still TSVs with chromosomal
      coordinates and other metadata, thus we can still treat them like bed
      files and filter based on the metadata as needed.

   2. Each of these is filtered and sorted to match the chromosome order of the
      reference FASTA in (1).
      
   3. In the case of diploid references, each haplotype may either be split into
      two FASTAs or combined into one. Regardless, the source bed files may be
      provided as either one or two files depending on what is available, and
      then either split/combined to match the FASTA.
  
3. Create stratifications using source files downloaded from (2) and other tools
   that run independently on the reference FASTA (such as `seqtk` or `GEM`).
   
4. If applicable, remove all gaps from each stratification (gaps stratication
   itself excepted).
   
5. Validate each stratification. For more details see README in the the 
   `validation` directory which is provided with all stratifications included 
   in this version.
   
6. If available, check each stratification against a previous version to assess
   differences (which may/may not be expected depending on the version).
   
7. Create tsv lists, MD5 hashes, documentation, and tarballs for final packaging
   and release.
   
# Reproducibility

### Version control

The snakemake pipeline itself is stored in git here: 

{{ pipeline_repo }}

The configuration that uses this pipeline, which in turn generated this
stratification set, is here:

{{ config_repo }}

The final stratification results should be fully determined by these two repos
(with minor caveats as discussed below).

{% if compare_txt is not none %}
### Stratification version comparisons

{{ compare_txt }}

Results can be found one level up from this directory under `validation`, and
the contained README will explain the various checks that were performed during
this comparison.

Any changes noted in this comparison (aside from `Union` and `Mappability` as
noted below) should be documented in the CHANGELOG in the configuration repo as
noted above.

{% endif -%}
### Source file provenance

For remote files, the snakemake configuration file allows for an MD5 hash of the
expected downloaded contents (note that in the case of compressed files, this
MD5 represents the hash of the contents and not the compressed archive, since
gzip headers can change depending on where/when they are compressed).

If any source file changes, the hashes will mismatch and the pipeline will
refuse to run. Thus the user is forced to acknowledge and document the change
if/when it happens.

This hash rule also applies to local files, but obviously this is not ideal as
local files are generally not sharable and is thus used sparingly if at all.

Bed files may also be specified directory in the configuration as coordinates,
in which case these are under revision control and thus reproducible.

### Conda environment specification

All snakemake environments fully specify the names and versions of all
dependencies (as shown with `conda env export`).

### External tools

Some tools are not provided in a conda environment (either because the package
doesn't exist or it is incompatible with other required packages).

In cases where the source is available, a specific version of the source is
downloaded and compiled on-the-fly during pipeline runtime.

In cases where only a binary is available, the binary is downloaded from a
specific version tag and then checksummed to determine validity.

### Non-determinism

The only known case of non-determinism happens with the `gem-mappability`
program (for reasons we don't understand). Even when run with the same
parameters, the output seems to be different on the order of a few hundred base
pairs when run on an entire reference. This difference is so tiny that it is
likely not meaningful or worth fixing, and the only way we can detect it is by
using the version comparison checks as noted above.

This only affects the `Mappability` category as well as the `Union` category
since this inherits from `Mappability`.
